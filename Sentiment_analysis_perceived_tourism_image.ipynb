{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "sagrada_clean_dataset = pd.read_csv(r'clean_dataset\\sagrada_clean_dataset.csv', encoding='utf-8',index_col=0)\n",
    "mila_clean_dataset = pd.read_csv(r'clean_dataset\\mila_clean_dataset.csv', encoding='utf-8',index_col=0)\n",
    "parkguell_clean_dataset = pd.read_csv(r'clean_dataset\\parkguell_clean_dataset.csv', encoding='utf-8',index_col=0)\n",
    "batllo_clean_dataset = pd.read_csv(r'clean_dataset\\batllo_clean_dataset.csv', encoding='utf-8',index_col=0)\n",
    "bcn_clean_dataset = pd.read_csv(r'clean_dataset\\bcndata_clean_dataset.csv', encoding='utf-8',index_col=0)\n",
    "\n",
    "alldata = pd.concat((sagrada_clean_dataset, mila_clean_dataset, parkguell_clean_dataset, batllo_clean_dataset,bcn_clean_dataset) ,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_official(user):\n",
    "    official_words = ['导游','旅行社','旅行','猫途鹰','巴特罗之家','摄影','酒店','房地产','国家展览','资讯','地接','包车','接待','代购','攻略','旅游网','加泰罗尼亚旅游官网','旅拍','有限公司']\n",
    "    for official_word in official_words:\n",
    "        if official_word in str(user):\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-44a049064391>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  no_oficial['iflocation'] = ['yes' if '西班牙' in str(x) else None for x in no_oficial['LOCATION']]\n"
     ]
    }
   ],
   "source": [
    "alldata['ifoficial'] = ['yes' if is_official(user) else None for user in alldata['USER']]\n",
    "image_ofi = alldata.dropna(subset = ['ifoficial'])\n",
    "no_oficial = alldata[alldata['ifoficial'] != 'yes']\n",
    "no_oficial['iflocation'] = ['yes' if '西班牙' in str(x) else None for x in no_oficial['LOCATION']]\n",
    "image_perci = no_oficial.dropna(subset = ['iflocation'])\n",
    "no_oficial_no_location = no_oficial[no_oficial['iflocation'] != 'yes']\n",
    "image_expect = no_oficial_no_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bixin import predict\n",
    "image_perci['score'] = image_perci['CONTENT'].astype(str).apply(predict)\n",
    "posi_perci = image_perci[image_perci['score'] > 0]\n",
    "nega_perci = image_perci[image_perci['score'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_topic_modeling(text = posi_perci[\"content_cutted\"],max_df_lda=0.1,min_df_lda=5, topics_number = 3, max_iter = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_topic_modeling(text = nega_perci[\"content_cutted\"],max_df_lda=0.2,min_df_lda=3, topics_number = 5, max_iter = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run sentiment_analysis_mydata.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#text1=image_perci.iloc[1,1]\n",
    "#sentiment_analysis(text1)\n",
    "image_perci['score'] = image_perci['CONTENT'].astype(str).apply(sentiment_analysis_mydata)\n",
    "image_perci\n",
    "#s.to_csv('test_sentiment_analysis.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_perci['score'] = image_perci['score'].astype(str)\n",
    "nega_perci = image_perci[image_perci['score'] == '[0]']\n",
    "nega_perci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nega_perci.to_csv('test_sentiment_analysis.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nega_perci[\"content_cutted\"] = nega_perci['CONTENT'].apply(chinese_word_segmentation)\n",
    "lda_topic_modeling(text = nega_perci[\"content_cutted\"],max_df_lda=0.2,min_df_lda=3, topics_number = 5, max_iter = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
